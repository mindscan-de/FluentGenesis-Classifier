{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore c2nes Parser\n",
    "(C) Maxim Gansert, 2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0,'../src')\n",
    "\n",
    "from com.github.c2nes.javalang import tokenizer, parser, ast\n",
    "from com.github.c2nes.javalang.tree import ClassDeclaration, ClassCreator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTokenizerForFile(filename):\n",
    "    with open(filename,\"rb\") as current_source_file:\n",
    "        all_lines_as_string = map(lambda line: line.decode('utf-8'), current_source_file.readlines()[0:])\n",
    "        current_source_code = \"\".join(all_lines_as_string) \n",
    "        return list(tokenizer.tokenize(current_source_code, ignore_errors=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = 'D:\\\\Downloads\\\\Big-Code-full\\\\java_projects\\\\'\n",
    "\n",
    "# only one class\n",
    "# some_source_filename = dataset_directory+'Algorithms\\\\src\\\\org\\\\rekdev\\\\trees\\\\BinaryTreeNode.java'\n",
    "\n",
    "# has multiple classes parallel in one compilation unit\n",
    "# some_source_filename = dataset_directory+'CSSMin\\\\CSSMin.java'\n",
    "\n",
    "# has nested classes\n",
    "# some_source_filename = dataset_directory+'cvs-plugin\\\\\\src\\\\\\main\\\\\\java\\\\\\hudson\\\\\\scm\\\\CVSChangeLogSet.java'\n",
    "\n",
    "# inner and/or anonymous classes\n",
    "some_source_filename = dataset_directory+'emf\\\\plugins\\\\org.eclipse.emf.codegen\\\\src\\\\org\\\\eclipse\\\\emf\\\\codegen\\\\CodeGen.java'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the java file\n",
    "java_tokenlist = runTokenizerForFile(some_source_filename)\n",
    "java_value_tokens = [x.value for x in java_tokenlist]\n",
    "\n",
    "\n",
    "# print (java_value_tokens)\n",
    "# print (java_tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the tree...\n",
    "parsed_tree = parser.parse(java_tokenlist)\n",
    "\n",
    "print (type(parsed_tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_method_body ( tokens ):\n",
    "    collect_mode = False\n",
    "    extracted_body = []\n",
    "    depth = 0\n",
    "    for token in tokens:\n",
    "        # don't collect the last closing brace token...\n",
    "        if token.value is '}':\n",
    "            depth-=1\n",
    "            if depth is 0:\n",
    "                collect_mode=False\n",
    "                # break this loop, since all is done / we have more closing braces than opening braces.\n",
    "                break\n",
    "        \n",
    "        if collect_mode:\n",
    "            extracted_body.append(token)\n",
    "\n",
    "        # don't collect the first open brace token...\n",
    "        if token.value is '{':\n",
    "            depth+=1\n",
    "            collect_mode = True\n",
    "\n",
    "    return extracted_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_method_tokens (index, collected_start_positions, java_tokenlist ):\n",
    "    collect_method_tokens = False\n",
    "    collected_method_tokens = []\n",
    "    \n",
    "    for token in java_tokenlist:\n",
    "        if token.position is collected_start_positions[index]:\n",
    "            collect_method_tokens = True\n",
    "        if index+1 not in collected_start_positions:\n",
    "            pass\n",
    "        else:\n",
    "            if token.position is collected_start_positions[index+1]:\n",
    "                collect_method_tokens = False\n",
    "            \n",
    "        if collect_method_tokens is True:\n",
    "            collected_method_tokens.append(token)\n",
    "            \n",
    "    return collected_method_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_method( method_index , collected_start_positions, java_tokenlist):\n",
    "    # the start positions are off by the modifiers, ans start at the type signature. \n",
    "    \n",
    "    # should be optimized into one method, since it is basically collecting a longer list with \"collect_method_teokens\" \n",
    "    # and then reducing it to a shorter version with \"extract_method_body\"\n",
    "    return extract_method_body ( collect_method_tokens( method_index, collected_start_positions, java_tokenlist ) ) \n",
    "\n",
    "# print(tokenizer.reformat_tokens(extract_method(10, collected_start_positions, java_tokenlist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_method_start_indexes_for_class( class_declaration ):\n",
    "    collected_start_positions = []\n",
    "    collected_method_names = []\n",
    "\n",
    "    for j in range(len(class_declaration.methods)):\n",
    "        # print(\"-- Methodname --\")\n",
    "        # print ( compilation_unit_ast.types[i].methods[j].name )\n",
    "        # print(\"-- position of method --\")\n",
    "        # print (compilation_unit_ast.types[i].methods[j].position )\n",
    "        # print (compilation_unit_ast.types[i].methods[j].modifiers)\n",
    "        collected_start_positions.append(class_declaration.methods[j].position)\n",
    "        collected_method_names.append(class_declaration.methods[j].name)\n",
    "        # print(\"-- Body of method --\")\n",
    "        # print ( compilation_unit_ast.types[i].methods[j].body )\n",
    "\n",
    "    return collected_start_positions, collected_method_names\n",
    "\n",
    "\n",
    "def extract_methods_from_class( class_declaration, java_tokenlist ):\n",
    "    extracted_methods = []\n",
    "    \n",
    "    collected_start_positions, collected_method_names = calculate_method_start_indexes_for_class(class_declaration)\n",
    "    \n",
    "    for index in range (len(collected_start_positions)):\n",
    "        method_for_index = extract_method( index, collected_start_positions, java_tokenlist)\n",
    "        method_dict_entry = {'method_body':method_for_index , 'method_name':collected_method_names[index]}\n",
    "        \n",
    "        extracted_methods.append(method_dict_entry)\n",
    "    \n",
    "    return extracted_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_classes_from_compilation_unit(compilation_unit_ast):\n",
    "    classes = []\n",
    "\n",
    "    for _,node in ast.walk_tree(compilation_unit_ast):\n",
    "        if isinstance(node, ClassDeclaration):\n",
    "            classes.append(node)\n",
    "        \n",
    "    [ print(clazz.name) for clazz in classes ]\n",
    "    # print (classes)\n",
    "    return classes\n",
    "\n",
    "extract_classes_from_compilation_unit(parsed_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def extract_allmethods_from_compilation_unit(compilation_unit_ast, java_tokenlist):\n",
    "    clazzes = extract_classes_from_compilation_unit(compilation_unit_ast)\n",
    "    \n",
    "    # I guess it would be better to use a walker, which is able to find each class_declaration, instead of iterating over the class only \n",
    "    for i in range(len(clazzes)):\n",
    "        class_declaration = clazzes[i]\n",
    "        extracted_methods = extract_methods_from_class(class_declaration, java_tokenlist )\n",
    "\n",
    "        for single_method in extracted_methods:\n",
    "            print(\"==[\"+single_method['method_name']+\"]==\")\n",
    "            print(tokenizer.reformat_tokens(single_method['method_body']))\n",
    "    pass\n",
    "\n",
    "\n",
    "extract_allmethods_from_compilation_unit(parsed_tree, java_tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "461.85px",
    "left": "8px",
    "right": "1291px",
    "top": "119px",
    "width": "621px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
